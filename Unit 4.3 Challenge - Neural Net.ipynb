{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some cancer imaging data from the University of Wisconsin, which includes 30 features of different images along with an ID number and a binary classification of the diagnosis (\"M\" for malignant, \"B\" for benign). We'll try a couple quick RF and SVM classifiers first to get a baseline accuracy, then see what happens when we run an RBM on the feature set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cancer = pd.read_csv(\"http://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/WDBC/WDBC.dat\"\n",
    "                      ,delimiter=\",\",header=None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis      2      3       4       5        6        7       8        9  \\\n",
       "0         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "1         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "2         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "3         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "4         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "       10   ...        22     23      24      25      26      27      28  \\\n",
       "0  0.2419   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "1  0.1812   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "2  0.2069   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "3  0.2597   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "4  0.1809   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "       29      30       31  \n",
       "0  0.2654  0.4601  0.11890  \n",
       "1  0.1860  0.2750  0.08902  \n",
       "2  0.2430  0.3613  0.08758  \n",
       "3  0.2575  0.6638  0.17300  \n",
       "4  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = cancer.drop(0,axis=1)\n",
    "cancer = cancer.rename(columns={1:'diagnosis'})\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a quick RFC and SVM classifier to see how well we do with baseline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop('diagnosis',axis=1)\n",
    "Y = cancer['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy: [0.93157895 0.97368421 0.97354497]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Not going to mess around with settings too much since we're hoping to just explore the performance boost\n",
    "# from using RBM\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "rfc_scores = cross_val_score(RFC,X,Y,scoring='accuracy')\n",
    "\n",
    "print('RFC Accuracy: {}'.format(rfc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: [0.96315789 0.98421053 0.97354497]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "SVC = SVC()\n",
    "\n",
    "svc_scores = cross_val_score(SVC,X_scaled,Y,scoring='accuracy')\n",
    "\n",
    "print('SVC Accuracy: {}'.format(svc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're already able to produce pretty solid accuracy given vanilla versions of SVM and RFC. But let's see how well we can do when tuning an RBM to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rbm__learning_rate': 1e-07, 'rbm__n_components': 3000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rbm_rfc = Pipeline(steps=[('rbm', BernoulliRBM()), ('rfc', RandomForestClassifier())])\n",
    "\n",
    "# Grid of parameters for our gridsearch optimization (done successively)\n",
    "param_grid = [\n",
    "    {\n",
    "        'rbm__learning_rate':[0.0000001,0.000001,0.00001],\n",
    "        'rbm__n_components': [20000,2500,3000]\n",
    "    },\n",
    "    { # Not really messing with RFC params since we're mostly interested in rbm impact\n",
    "    },\n",
    "]\n",
    "\n",
    "GS = GridSearchCV(rbm_rfc,param_grid,scoring='accuracy')\n",
    "GS.fit(X,Y)\n",
    "\n",
    "print(GS.best_params_)\n",
    "best_params = GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbm_rfc Accuracy: [0.96315789 0.97368421 0.97883598]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Using best params from grid search exercise\n",
    "rbm_rfc = Pipeline(steps=[('rbm', BernoulliRBM(learning_rate=1e-07,n_components= 3000)), ('rfc', RandomForestClassifier())])\n",
    "\n",
    "rbm_rfc.fit(X,Y)\n",
    "\n",
    "rbm_rfc_scores = cross_val_score(rbm_rfc,X_scaled,Y,scoring='accuracy')\n",
    "\n",
    "print('rbm_rfc Accuracy: {}'.format(rbm_rfc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar accuracy to our vanilla RFC but a slight improvement, which is to say that the model does pretty well. But we're not seeing a vast improvement as we might have expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rbm__learning_rate': 0.1, 'rbm__n_components': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rbm_svc = Pipeline(steps=[('rbm', BernoulliRBM()), ('svm', SVC())])\n",
    "\n",
    "# Grid of parameters for our gridsearch optimization (done successively)\n",
    "param_grid = [\n",
    "    {\n",
    "        'rbm__learning_rate':[0.1, 0.00000001],\n",
    "        'rbm__n_components': [100,200,300,1000,2000]\n",
    "    },\n",
    "    {\n",
    "    },\n",
    "]\n",
    "\n",
    "GS = GridSearchCV(rbm_svc,param_grid,scoring='accuracy')\n",
    "GS.fit(X_scaled,Y)\n",
    "\n",
    "print(GS.best_params_)\n",
    "best_params = GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbm_svc Accuracy: [0.90526316 0.91578947 0.92063492]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Using best params from grid search exercise\n",
    "rbm_svc = Pipeline(steps=[('rbm', BernoulliRBM(learning_rate=0.1,n_components= 100)), ('svc', SVC())])\n",
    "\n",
    "rbm_svc.fit(X_scaled,Y)\n",
    "\n",
    "rbm_svc_scores = cross_val_score(rbm_svc,X_scaled,Y,scoring='accuracy')\n",
    "\n",
    "print('rbm_svc Accuracy: {}'.format(rbm_svc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBM doesn't seem to be particularly useful when used in conjunction with our SVM classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding Thoughts on RBM\n",
    "The task was to use RBM on a dataset of image data to improve results, which we did. We were able to improve results ever so slightly for RFC, but it turns out we weren't using the best dataset to demonstrate the capabilities of RBM in feature extraction for this type of data. RBM is particularly useful when the raw data is not conducive to modeling, but our variables actually were quite ready to be modeled on already. As a result, the accuracy from vanilla RFC and SVC were already extremely high, making it difficult to demonstrate vast improvement from RBM.\n",
    "\n",
    "Just for fun, let's see how an MLP does on this same dataset...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5000, 5000, 5000), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model (tried diff variations on num layers and their size)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5000,5000,5000,))\n",
    "mlp.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp Accuracy: [0.68421053 0.93157895 0.37037037]\n"
     ]
    }
   ],
   "source": [
    "mlp_scores = cross_val_score(mlp,X,Y,scoring='accuracy')\n",
    "\n",
    "print('mlp Accuracy: {}'.format(mlp_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does OK, but given the excessive runtime and middling results relative to the RFC and SVM classifiers, probably wouldn't be our model of choice. We know that RBMs typically like LOTS of data, and we only have ~500 or so observations, so that could be why this model is underperforming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
