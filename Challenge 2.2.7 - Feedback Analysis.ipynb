{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "amazon = pd.read_table(\"amazon.txt\",header=None)\n",
    "yelp = pd.read_table(\"yelp.txt\",header=None)\n",
    "\n",
    "amazon.columns = ['text','positive']\n",
    "yelp.columns = ['text','positive']\n",
    "\n",
    "# Make outcome column boolean\n",
    "amazon['positive'] = amazon['positive'] == 1\n",
    "yelp['positive'] = yelp['positive'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the Amazon data and use that to train a naive bayes model for predicting sentiment. The first step is to define which keywords would indicate a positive or negative review. My initial approach was to create lists of terms that I thought would be positive or negative, but I eventually settled on a more programmatic approach. Let's split the data into those with a negative review and those with a positive. Then, let's calculate the most common words in each of those datasets. Next, remove any duplicates, since these are likely common words like \"the\", or will be indeterminate in whether they indicate a good or bad review. We'll feed these into the model and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all text columns into a list of words\n",
    "amazon['text'] = np.array(amazon['text'].str.lower().str.split(\" |,|\\.|!|\\?\"))\n",
    "\n",
    "# Creating positive and negative subsets to calculate most popular words for pos & neg\n",
    "amazon_pos = amazon[amazon['positive'] == 1]\n",
    "amazon_neg = amazon[amazon['positive'] == 0]\n",
    "\n",
    "# Calculate most common words in positive & negative reviews\n",
    "x = sum(amazon_pos['text'], [])\n",
    "y = sum(amazon_neg['text'], [])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "for item in x:\n",
    "    c = Counter(x)\n",
    "    common_tuples = c.most_common(200)\n",
    "    top_pos_words = [i[0] for i in common_tuples]\n",
    "\n",
    "for item in y:\n",
    "    c = Counter(y)\n",
    "    common_tuples = c.most_common(200)\n",
    "    top_neg_words = [i[0] for i in common_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove overlapping words for each\n",
    "pos_unique = [x for x in top_pos_words if x not in top_neg_words]\n",
    "neg_unique = [x for x in top_neg_words if x not in top_pos_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 74\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_unique),len(neg_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['works', 'excellent', 'price', 'best', 'nice', 'love', 'easy', 'comfortable', 'happy', 'fine', 'been', 'far', 'clear', 'device', 'cell', 'fits', 'camera', 'got', 'working', 'highly', 'pretty', 'years', 'without', 'everything', 'cool', 'wear', 'lot', 'jabra', 'people', 'found', 'both', 'light', 'perfectly', 'value', 'impressed', 'say', 'priced', 'sturdy', 'gets', 'little', 'tried', 'definitely', 'pleased', 'small', 'voice', 'awesome', 'overall', 'range', 'amazon', 'cases', 'original', 'ears', 'seems', 'keyboard', 'their', 'several', 'most', 'headsets', 'verizon', 'order', 'free', 'shipping', 'pictures', 'leather', 'fast', 'comfortably', 'job', '&', 'glad', 'phones', 'look', 'charm', 'being', 'simple']\n"
     ]
    }
   ],
   "source": [
    "print(pos_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['money', 'first', 'then', 'do', 'poor', 'waste', \"doesn't\", 'bad', 'what', 'could', 'worst', 'will', 'calls', 'off', 'same', 'piece', 'hear', 'charge', 'disappointed', 'enough', 'thing', 'terrible', 'plug', 'volume', 'design', 'horrible', 'customer', 'junk', 'unit', 'by', 'how', \"didn't\", 'talk', 'broke', 'over', 'useless', 'back', 'however', 'last', 'went', '3', 'days', 'buttons', 'months', 'completely', 'stay', 'company', 'never', 'crap', 'difficult', 'cheap', 'way', 'dropped', 'we', 'big', 'week', 'within', 'down', '1', 'signal', 'put', 'some', 'disappointment', 'return', 'old', 'nokia', 'want', 'anything', 'disappointing', 'picture', 'low', 'anyone', 'none', 'easily']\n"
     ]
    }
   ],
   "source": [
    "print(neg_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [so, there, is, no, way, for, me, to, plug, it...\n",
      "1                     [good, case, , excellent, value, ]\n",
      "2                           [great, for, the, jawbone, ]\n",
      "3      [tied, to, charger, for, conversations, lastin...\n",
      "4                                [the, mic, is, great, ]\n",
      "5      [i, have, to, jiggle, the, plug, to, get, it, ...\n",
      "6      [if, you, have, several, dozen, or, several, h...\n",
      "7      [if, you, are, razr, owner, , , you, must, hav...\n",
      "8          [needless, to, say, , i, wasted, my, money, ]\n",
      "9             [what, a, waste, of, money, and, time, , ]\n",
      "10               [and, the, sound, quality, is, great, ]\n",
      "11     [he, was, very, impressed, when, going, from, ...\n",
      "12     [if, the, two, were, seperated, by, a, mere, 5...\n",
      "13                         [very, good, quality, though]\n",
      "14     [the, design, is, very, odd, , as, the, ear, \"...\n",
      "15     [highly, recommend, for, any, one, who, has, a...\n",
      "16          [i, advise, everyone, do, not, be, fooled, ]\n",
      "17                               [so, far, so, good, , ]\n",
      "18                                    [works, great, , ]\n",
      "19     [it, clicks, into, place, in, a, way, that, ma...\n",
      "20     [i, went, on, motorola's, website, and, follow...\n",
      "21     [i, bought, this, to, use, with, my, kindle, f...\n",
      "22      [the, commercials, are, the, most, misleading, ]\n",
      "23     [i, have, yet, to, run, this, new, battery, be...\n",
      "24     [i, bought, it, for, my, mother, and, she, had...\n",
      "25          [great, pocket, pc, /, phone, combination, ]\n",
      "26     [i've, owned, this, phone, for, 7, months, now...\n",
      "27     [i, didn't, think, that, the, instructions, pr...\n",
      "28     [people, couldnt, hear, me, talk, and, i, had,...\n",
      "29                             [doesn't, hold, charge, ]\n",
      "                             ...                        \n",
      "970    [i, plugged, it, in, only, to, find, out, not,...\n",
      "971                               [excellent, product, ]\n",
      "972                    [earbud, piece, breaks, easily, ]\n",
      "973                                   [lousy, product, ]\n",
      "974    [this, phone, tries, very, hard, to, do, every...\n",
      "975    [it, is, the, best, charger, i, have, seen, on...\n",
      "976                              [sweetest, phone, , , ]\n",
      "977     [:-)oh, , the, charger, seems, to, work, fine, ]\n",
      "978    [it, fits, so, securely, that, the, ear, hook,...\n",
      "979                              [not, enough, volume, ]\n",
      "980          [echo, problem, , , , very, unsatisfactory]\n",
      "981    [you, could, only, take, 2, videos, at, a, tim...\n",
      "982                        [don't, waste, your, money, ]\n",
      "983    [i, am, going, to, have, to, be, the, first, t...\n",
      "984    [adapter, does, not, provide, enough, charging...\n",
      "985    [there, was, so, much, hype, over, this, phone...\n",
      "986    [you, also, cannot, take, pictures, with, it, ...\n",
      "987                        [phone, falls, out, easily, ]\n",
      "988    [it, didn't, work, , people, can, not, hear, m...\n",
      "989    [the, text, messaging, feature, is, really, tr...\n",
      "990    [i'm, really, disappointed, all, i, have, now,...\n",
      "991                            [painful, on, the, ear, ]\n",
      "992            [lasted, one, day, and, then, blew, up, ]\n",
      "993                                     [disappointed, ]\n",
      "994                          [kind, of, flops, around, ]\n",
      "995    [the, screen, does, get, smudged, easily, beca...\n",
      "996    [what, a, piece, of, junk, , , i, lose, more, ...\n",
      "997                  [item, does, not, match, picture, ]\n",
      "998    [the, only, thing, that, disappoint, me, is, t...\n",
      "999    [you, can, not, answer, calls, with, the, unit...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(amazon['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 1000 observations, there were 186 incorrect predictions from our model.\n",
      "Or in other words, our model was wrong 18.6 percent of the time.\n"
     ]
    }
   ],
   "source": [
    "# Creating the features based on our words\n",
    "for word in pos_unique + neg_unique:\n",
    "    amazon[word] = amazon['text'].apply(lambda x: word in x)\n",
    "    yelp[word] = yelp['text'].apply(lambda x: word in x) #Creating the necessary feature for Yelp to use down the road\n",
    "    \n",
    "# Set up the outcome variable and model vars\n",
    "variables = amazon[pos_unique + neg_unique]\n",
    "outcome = amazon['positive']\n",
    "\n",
    "# Import model, instantiate, and train\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bernoulli = BernoulliNB()\n",
    "bernoulli.fit(variables, outcome)\n",
    "\n",
    "# Store predictions, add as a df column\n",
    "predictions = bernoulli.predict(variables)\n",
    "amazon['predictions'] = predictions\n",
    "\n",
    "# Add column for whether or not prediction was accurate for said observation\n",
    "amazon['accurate'] =  amazon['predictions'] == amazon['positive']\n",
    "wrong_predictions = amazon['accurate'].value_counts(dropna=False).loc[False]\n",
    "observations = len(amazon['accurate'])\n",
    "print('Of {} observations, there were {} incorrect predictions from our model.'.format(observations, wrong_predictions))\n",
    "print('Or in other words, our model was wrong {:.1f} percent of the time.'.format((wrong_predictions/observations) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good! My alternate model, in which I just guessed corresponding good or bad keywords, had an error rate north of 30%.\n",
    "\n",
    "Next, let's see how well this fits the other data (Yelp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 1000 observations, there were 361 incorrect predictions from our model.\n",
      "Or in other words, our model was wrong 36.1 percent of the time.\n"
     ]
    }
   ],
   "source": [
    "# Set up the outcome variable and model vars\n",
    "yelp_vars = yelp[pos_unique + neg_unique]\n",
    "\n",
    "# Store predictions, add as a df column\n",
    "yelp_predictions = bernoulli.predict(yelp_vars)\n",
    "yelp['predictions'] = yelp_predictions\n",
    "\n",
    "# Add column for whether or not prediction was accurate for said observation\n",
    "yelp['accurate'] =  yelp['predictions'] == yelp['positive']\n",
    "wrong_predictions = yelp['accurate'].value_counts(dropna=False).loc[False]\n",
    "observations = len(yelp['accurate'])\n",
    "print('Of {} observations, there were {} incorrect predictions from our model.'.format(observations, wrong_predictions))\n",
    "print('Or in other words, our model was wrong {:.1f} percent of the time.'.format((wrong_predictions/observations) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The above isn't great, but it's not terrible either! I think the flaw might be that I'm bringing in the most common words featured in positive and negative reviews, but not necessarily the values that are __likeliest__ to exist in a positive or negative review. Let's try doing that quickly.\n",
    "\n",
    "______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_table(\"amazon.txt\",header=None)\n",
    "yelp = pd.read_table(\"yelp.txt\",header=None)\n",
    "\n",
    "amazon.columns = ['text','positive']\n",
    "yelp.columns = ['text','positive']\n",
    "\n",
    "# Make outcome column boolean\n",
    "amazon['positive'] = amazon['positive'] == 1\n",
    "yelp['positive'] = yelp['positive'] == 1\n",
    "\n",
    "# Converting all text columns into a list of words\n",
    "amazon['text'] = np.array(amazon['text'].str.lower().str.split(\" |,|\\.|!|\\?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_words = sum(amazon['text'], [])\n",
    "wordset = set(all_words)\n",
    "wordsdf=pd.DataFrame()\n",
    "\n",
    "# Create df with all of the correlations to positive, by word\n",
    "for word in wordset:\n",
    "    wordsdf[word] = amazon['text'].apply(lambda x: word in x)\n",
    "\n",
    "wordsdf['positive'] = amazon['positive']\n",
    "\n",
    "#calculate correlations\n",
    "correlations = wordsdf.corr().filter(['positive']).drop(['positive'])\n",
    "pos_correlations = correlations.abs().sort_values('positive',ascending=False)\n",
    "\n",
    "#old, inefficient way\n",
    "#correlations = wordsdf.corr()\n",
    "#pos_correlations = correlations.abs().sort_values('positive',ascending=False).loc[:,'positive']\n",
    "\n",
    "#let's take the top 50\n",
    "features = pos_correlations[:100].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 1000 observations, there were 157 incorrect predictions from our model.\n",
      "Or in other words, our model was wrong 15.7 percent of the time.\n"
     ]
    }
   ],
   "source": [
    "# Add these words as features to the df\n",
    "for word in features:\n",
    "    amazon[word] = amazon['text'].apply(lambda x: word in x)\n",
    "    yelp[word] = yelp['text'].apply(lambda x: word in x) #Creating the necessary feature for Yelp to use down the road\n",
    "    \n",
    "# Set up the outcome variable and model vars\n",
    "variables = amazon[features]\n",
    "outcome = amazon['positive']\n",
    "\n",
    "# Import model, instantiate, and train\n",
    "bernoulli.fit(variables, outcome)\n",
    "\n",
    "# Store predictions, add as a df column\n",
    "predictions = bernoulli.predict(variables)\n",
    "amazon['predictions'] = predictions\n",
    "\n",
    "# Add column for whether or not prediction was accurate for said observation\n",
    "amazon['accurate'] =  amazon['predictions'] == amazon['positive']\n",
    "wrong_predictions = amazon['accurate'].value_counts(dropna=False).loc[False]\n",
    "observations = len(amazon['accurate'])\n",
    "print('Of {} observations, there were {} incorrect predictions from our model.'.format(observations, wrong_predictions))\n",
    "print('Or in other words, our model was wrong {:.1f} percent of the time.'.format((wrong_predictions/observations) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! Now let's see how well it did with Yelp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of 1000 observations, there were 314 incorrect predictions from our model.\n",
      "Or in other words, our model was wrong 31.4 percent of the time.\n"
     ]
    }
   ],
   "source": [
    "# Set up the outcome variable and model vars\n",
    "yelp_vars = yelp[features]\n",
    "\n",
    "# Store predictions, add as a df column\n",
    "yelp_predictions = bernoulli.predict(yelp_vars)\n",
    "yelp['predictions'] = yelp_predictions\n",
    "\n",
    "# Add column for whether or not prediction was accurate for said observation\n",
    "yelp['accurate'] =  yelp['predictions'] == yelp['positive']\n",
    "wrong_predictions = yelp['accurate'].value_counts(dropna=False).loc[False]\n",
    "observations = len(yelp['accurate'])\n",
    "print('Of {} observations, there were {} incorrect predictions from our model.'.format(observations, wrong_predictions))\n",
    "print('Or in other words, our model was wrong {:.1f} percent of the time.'.format((wrong_predictions/observations) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also slightly better. Interesting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
